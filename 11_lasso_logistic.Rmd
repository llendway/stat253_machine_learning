---
title: "Lasso with Logistic"
output: 
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r, echo=FALSE}
#plotting and exploring
library(tidyverse) #for plotting and summarizing
library(GGally) #for nice scatterplot matrix 
library(ggridges) #for joy/ridge plots
library(corrplot) #for basic correlation matrix plot
library(naniar) #for exploring missing values
library(pdp) #for partial dependence plots, MARS models
library(rpart.plot) #for plotting decision trees
library(vip) #for importance plots
library(pROC) #for ROC curves
library(plotROC) #for plotting ROC curves

#making things look nice
library(lubridate) #for nice dates
library(knitr) #for nice tables
library(scales) #for nice labels on graphs
library(gridExtra) #for arranging plots
library(broom) #for nice model output
library(janitor) #for nice names

#data
library(ISLR) #for data
library(moderndive) #for data
library(rattle) #weather data

#modeling
library(rsample) #for splitting data
library(recipes) #for keeping track of transformations
library(caret) #for modeling
library(leaps) #for variable selection
library(glmnet) #for LASSO
library(earth) #for MARS models
library(rpart) #for decision trees
library(randomForest) #for bagging and random forests

theme_set(theme_minimal())
```

# Lasso in Logistic Models

In logistic regression, the coefficients are found using maximum likelihood. So, find $\beta$s that maximize:

$$
\prod_{i=1}^n p(y_i = 1 |x_i)^{y_i}(1-p(y_i = 1|x_i))^{1-y_i}
$$

Maximizing the quantity above is the same as minimizing the negative of that,

$$
-\prod_{i=1}^n p(y_i = 1 |x_i)^{y_i}(1-p(y_i = 1|x_i))^{1-y_i}
$$

The lasso method for logistic regression, instead minimizes

$$
-\prod_{i=1}^n p(y_i = 1 |x_i)^{y_i}(1-p(y_i = 1|x_i))^{1-y_i}
 + \lambda \sum_{j=1}^p |\beta_j|,  \text{  where  } \lambda\ge 0
$$

This is the same *shrinkage penalty* that was used in the lasso for linear models. And that penalty term will force some of the coefficients to be zero, just like it did in regular linear regression. 

# Implementing in `caret`

```{r, eval=FALSE}
set.seed(___)

# Perform lasso
logistic_lasso_model <- train(
    y ~ x,
    data = ___,
    method = "glmnet",
    family = "binomial",
    trControl = trainControl(method = "cv", number = ___),
    tuneGrid = data.frame(alpha = 1, 
                          lambda = ___), #sequence of lambda values to try - can vary depending on context
    metric = "Accuracy",
    na.action = na.omit
)
```


# Short Exercises

**I will post solutions to these before Thursday.**

We will use the dataset `syndey_train_smaller` again for this analysis. I got rid of a few variables that had a lot of missing values and imputed (filled in) the other missing values with the median for that variable.

```{r}
#load and process weather data for Sydney
data("weatherAUS")

set.seed(253)
sydney_split <- weatherAUS %>% 
  filter(Location == "Sydney") %>% 
  initial_split(prop = .7, strata = RainTomorrow)

sydney_train <- training(sydney_split)
sydney_test <- testing(sydney_split)

table(sydney_train$RainTomorrow) %>% 
  prop.table()

table(sydney_test$RainTomorrow) %>% 
  prop.table()
```

```{r}
sydney_train_smaller <- sydney_train %>% 
  select(-WindGustDir, -WindGustSpeed, 
         -Cloud9am, -Cloud3pm,
         -Location, -Date, -RISK_MM) %>% 
  mutate(WindDir3pm = factor(WindDir3pm, ordered = FALSE),
         WindDir9am = factor(WindDir9am, ordered = FALSE)) %>% 
  impute_median_all()
```


1. Use the lasso technique for variable selection. Use all the variables in the `sydney_train_smaller` dataset to predict `RainTomorrow`. I have started the code below. Delete the `eval=FALSE` when you are finished. 

```{r, eval=FALSE}
set.seed(253)

lambda_grid <- 10^seq(-4, -2, length = 100)

sydney_lasso_model <- train(
    ___ ~ .,
    data = sydney_train_smaller,
    method = "___",
    family = "___",
    trControl = trainControl(method = "cv", number = 5),
    tuneGrid = data.frame(alpha = 1, 
                          lambda = ___),
    metric = "Accuracy",
    na.action = na.omit
)

```

2. Use the `results` from the model to create a graph of $\lambda$ on the x-axis and `Accuracy` on the y-axis. 

3. Find the best $\lambda$, the one with the smallest cross-validated Accuracy. 

4. Print the coefficients from the best model. How many coefficients are zero?

5. Create the confusion matrix. Report and interpret the Sensitivity (True Positive Rate). How would it change if we would use a lower cutoff value than the default 0.5?

6. We can tune our model on something other than `Accuracy`. The code below uses area under the ROC curve (abbreviated `ROC`) to find the best model. How does this model compare to the model optimized by `Accuracy`? Print out the coefficients.

```{r}
sydney_lasso_model2 <- train(
    as.factor(RainTomorrow) ~ .,
    data = sydney_train_smaller,
    method = "glmnet",
    family = "binomial",
    trControl = trainControl(method = "cv", 
                             number = 5,
                             classProbs = TRUE,
                             summaryFunction = twoClassSummary),
    tuneGrid = data.frame(alpha = 1, 
                          lambda = 10^seq(-4, -2, length = 100)),
    metric = "ROC",
    na.action = na.omit
)

```


